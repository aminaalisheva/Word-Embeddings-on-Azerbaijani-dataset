{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminaalisheva/Word-Embeddings-on-Azerbaijani-dataset/blob/main/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClwgebfjKtUT"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.corpus import reuters\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIgbANplKtUY",
        "outputId": "632826c1-4253-43e4-fae6-e17fc279f4f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_11439/122502440.py:2: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove_model = glove2word2vec(\"../glove/vectors.txt\", \"w2v.txt\")\n"
          ]
        }
      ],
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove_model = glove2word2vec(\"../glove/vectors.txt\", \"w2v.txt\")\n",
        "w2v_model = Word2Vec.load(\"../word2vec3.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFvQH5LTKtUc",
        "outputId": "8efb9063-628a-40fc-87d9-12b33fbc336f"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'most_similar'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m words_test \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbank\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbazar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpul\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticarət\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msəhm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqızıl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minkişaf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqiymət\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msərmayə\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalyuta\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words_test:\n\u001b[0;32m----> 3\u001b[0m     synonyms \u001b[38;5;241m=\u001b[39m \u001b[43mglove_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_similar\u001b[49m(word, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      4\u001b[0m     synonyms \u001b[38;5;241m=\u001b[39m [i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m synonyms]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, synonyms)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'most_similar'"
          ]
        }
      ],
      "source": [
        "words_test = ['bank', 'bazar', 'pul', 'ticarət', 'səhm', 'qızıl', 'inkişaf', 'qiymət', 'sərmayə', 'valyuta']\n",
        "for word in words_test:\n",
        "    synonyms = glove_model.most_similar(word, topn=5)\n",
        "    synonyms = [i[0] for i in synonyms]\n",
        "    print(f\"{word}:\", synonyms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHfIhsVJKtUe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"hf://datasets/hajili/azsci_topics/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alY0o07SKtUi",
        "outputId": "de82bbc5-706d-46b1-b1d6-a8500e7edd0d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>topic</th>\n",
              "      <th>subtopic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Birbaşa xarici investisiyaların İordaniyanın i...</td>\n",
              "      <td>İqtisad elmləri</td>\n",
              "      <td>Dünya iqtisadiyyatı</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Uşaqlarda çənə sümüyünün travmatik zədələnmələ...</td>\n",
              "      <td>Tibb elmləri</td>\n",
              "      <td>Stomatologiya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Çıxmayan ortodontik qurğularla müalicə zamanı ...</td>\n",
              "      <td>Tibb elmləri</td>\n",
              "      <td>Stomatologiya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XIX əsrin ikinci yarısında Cənubi Azarbaycan ə...</td>\n",
              "      <td>Filologiya elmləri</td>\n",
              "      <td>Azərbaycan ədəbiyyatı</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bəkir Çobanzadənin elmi və bədii yaradıcılığın...</td>\n",
              "      <td>Filologiya elmləri</td>\n",
              "      <td>Folklorşünaslıq</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title               topic  \\\n",
              "3  Birbaşa xarici investisiyaların İordaniyanın i...     İqtisad elmləri   \n",
              "4  Uşaqlarda çənə sümüyünün travmatik zədələnmələ...        Tibb elmləri   \n",
              "5  Çıxmayan ortodontik qurğularla müalicə zamanı ...        Tibb elmləri   \n",
              "6  XIX əsrin ikinci yarısında Cənubi Azarbaycan ə...  Filologiya elmləri   \n",
              "7  Bəkir Çobanzadənin elmi və bədii yaradıcılığın...  Filologiya elmləri   \n",
              "\n",
              "                subtopic  \n",
              "3    Dünya iqtisadiyyatı  \n",
              "4          Stomatologiya  \n",
              "5          Stomatologiya  \n",
              "6  Azərbaycan ədəbiyyatı  \n",
              "7        Folklorşünaslıq  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.dropna()\n",
        "top_topics = df['topic'].value_counts().nlargest(4).index\n",
        "df = df[df['topic'].isin(top_topics)]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS72TRDAKtUl",
        "outputId": "2311ca74-2ba2-4be9-de3d-744fa6c61e80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "topic\n",
              "Filologiya elmləri    1008\n",
              "Tibb elmləri           661\n",
              "İqtisad elmləri        655\n",
              "Texnika elmləri        550\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"topic\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u25kwOWnKtUo"
      },
      "outputs": [],
      "source": [
        "docs = list(df[\"title\"])\n",
        "targets = list(df[\"topic\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4bOKvieKtUr"
      },
      "outputs": [],
      "source": [
        "# Task 5: Text Classification using Logistic Regression\n",
        "# Example classification: categories from Reuters\n",
        "# targets = [reuters.categories(fid)[0] if reuters.categories(fid) else 'none' for fid in reuters.fileids()[:500]]\n",
        "X_train, X_test, y_train, y_test = train_test_split(docs, targets, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0macFDWKtUu",
        "outputId": "8a6d9dae-a0b1-400d-ce67-8e171e04b75a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report using Count Vectorizer:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "Filologiya elmləri       0.93      0.99      0.96       316\n",
            "   Texnika elmləri       0.95      0.91      0.93       162\n",
            "      Tibb elmləri       0.98      0.92      0.95       196\n",
            "   İqtisad elmləri       0.95      0.95      0.95       189\n",
            "\n",
            "          accuracy                           0.95       863\n",
            "         macro avg       0.96      0.94      0.95       863\n",
            "      weighted avg       0.95      0.95      0.95       863\n",
            "\n",
            "Classification Report using TF-IDF Vectorizer:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "Filologiya elmləri       0.97      0.98      0.97       316\n",
            "   Texnika elmləri       0.94      0.94      0.94       162\n",
            "      Tibb elmləri       0.97      0.95      0.96       196\n",
            "   İqtisad elmləri       0.95      0.95      0.95       189\n",
            "\n",
            "          accuracy                           0.96       863\n",
            "         macro avg       0.96      0.95      0.96       863\n",
            "      weighted avg       0.96      0.96      0.96       863\n",
            "\n",
            "Classification Report using Word2Vec Embeddings:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "Filologiya elmləri       0.97      0.96      0.97       316\n",
            "   Texnika elmləri       0.66      0.61      0.64       162\n",
            "      Tibb elmləri       0.70      0.75      0.72       196\n",
            "   İqtisad elmləri       0.88      0.89      0.89       189\n",
            "\n",
            "          accuracy                           0.83       863\n",
            "         macro avg       0.80      0.80      0.80       863\n",
            "      weighted avg       0.83      0.83      0.83       863\n",
            "\n",
            "Classification Report using GloVe Embeddings:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "Filologiya elmləri       0.37      1.00      0.54       316\n",
            "   Texnika elmləri       0.00      0.00      0.00       162\n",
            "      Tibb elmləri       0.00      0.00      0.00       196\n",
            "   İqtisad elmləri       0.00      0.00      0.00       189\n",
            "\n",
            "          accuracy                           0.37       863\n",
            "         macro avg       0.09      0.25      0.13       863\n",
            "      weighted avg       0.13      0.37      0.20       863\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jafar/ada/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/home/jafar/ada/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/home/jafar/ada/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Vectorization methods\n",
        "vectorizers = {\n",
        "    'Count': CountVectorizer(),\n",
        "    'TF-IDF': TfidfVectorizer()\n",
        "}\n",
        "\n",
        "for name, vect in vectorizers.items():\n",
        "    X_train_vect = vect.fit_transform(X_train)\n",
        "    X_test_vect = vect.transform(X_test)\n",
        "    clf = LogisticRegression(max_iter=200)\n",
        "    clf.fit(X_train_vect, y_train)\n",
        "    y_pred = clf.predict(X_test_vect)\n",
        "    print(f'Classification Report using {name} Vectorizer:\\n', classification_report(y_test, y_pred))\n",
        "\n",
        "# Using Word2Vec & GloVe embeddings as features\n",
        "\n",
        "def doc_embedding(model, documents):\n",
        "    embeddings = []\n",
        "    for doc in documents:\n",
        "        words = [word for word in doc.lower().split() if word in model]\n",
        "        if words:\n",
        "            embeddings.append(np.mean(model[words], axis=0))\n",
        "        else:\n",
        "            embeddings.append(np.zeros(16))\n",
        "    return np.array(embeddings)\n",
        "\n",
        "for name, model in [('Word2Vec', w2v_model.wv), ('GloVe', glove_model)]:\n",
        "    X_train_emb = doc_embedding(model, X_train)\n",
        "    X_test_emb = doc_embedding(model, X_test)\n",
        "    clf = LogisticRegression(max_iter=200)\n",
        "    clf.fit(X_train_emb, y_train)\n",
        "    y_pred = clf.predict(X_test_emb)\n",
        "    print(f'Classification Report using {name} Embeddings:\\n', classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhAOhKByKtUx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}